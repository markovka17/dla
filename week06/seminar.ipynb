{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meO-Mp9jiAFC",
    "outputId": "3ce0c838-cd55-4199-e590-2116cd25d35f"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 256\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    num_epochs: int = 25\n",
    "    n_mels: int = 40\n",
    "    kernel_size: int = 16\n",
    "    stride: int = 10\n",
    "    hidden_size: int = 128\n",
    "    gru_num_layers: int = 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhDvVqcZh9pI",
    "outputId": "5fb1e87d-51ba-447d-f6b7-058e0360304c"
   },
   "outputs": [],
   "source": [
    "!wget https://gist.githubusercontent.com/Kirili4ik/6ac5c745ff8dad094e9c464c08f66f3e/raw/63daacc17f52a7d90f7f4166a3f5deef62b165db/dataset_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "QKgGdL8jh9pJ",
    "outputId": "faf10e67-60ce-4de9-f97a-39bcc81bfd24"
   },
   "outputs": [],
   "source": [
    "from dataset_utils import DatasetDownloader, TrainDataset\n",
    "\n",
    "dataset_downloader = DatasetDownloader(TaskConfig.keyword)\n",
    "labeled_data, _ = dataset_downloader.generate_labeled_data()\n",
    "\n",
    "labeled_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = torchaudio.load(self.background_noises[noise_num])[0].squeeze()\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(low=0, high=int(\n",
    "            noise.size(0) - audio.size(0) - 1), size=(1,)).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "indexes = torch.randperm(len(labeled_data))\n",
    "train_indexes = indexes[:int(len(labeled_data) * 0.8)]\n",
    "val_indexes = indexes[int(len(labeled_data) * 0.8):]\n",
    "\n",
    "train_df = labeled_data.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = labeled_data.iloc[val_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDPLht5fqUYe"
   },
   "outputs": [],
   "source": [
    "# Sample is a dict of utt, word and label\n",
    "transform_tr = AugsCreation()\n",
    "train_set = TrainDataset(df=train_df, kw=TaskConfig.keyword, transform=transform_tr)\n",
    "val_set = TrainDataset(df=val_df, kw=TaskConfig.keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.df['label'].values)\n",
    "val_sampler = get_sampler(val_set.df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['utt'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler)\n",
    "#                           num_workers=2, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        sampler=val_sampler,\n",
    "                        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec():\n",
    "\n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,  n_mels=config.n_mels),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26_QtIlXqUYl"
   },
   "outputs": [],
   "source": [
    "# Pay attention to _groups_ param\n",
    "\n",
    "def SepConv(in_size, out_size, kernel_size, stride, padding=0):\n",
    "    return nn.Sequential(\n",
    "        torch.nn.Conv1d(in_size, in_size, kernel_size,\n",
    "                        stride=stride, groups=in_size,\n",
    "                        padding=padding),\n",
    "\n",
    "        torch.nn.Conv1d(in_size, out_size, kernel_size=1,\n",
    "                        stride=1, groups=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIT6STF_qUYl"
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.sepconv = SepConv(in_size=config.n_mels, out_size=config.hidden_size,\n",
    "                               kernel_size=config.kernel_size, stride=config.stride)\n",
    "\n",
    "        self.gru = nn.GRU(input_size=config.hidden_size, hidden_size=config.hidden_size,\n",
    "                          num_layers=config.gru_num_layers,\n",
    "                          dropout=0.1,\n",
    "                          bidirectional=config.bidirectional)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.sepconv(x)\n",
    "\n",
    "        # (BS, hidden, seq_len) ->(seq_len, BS, hidden)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        # x : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHZTwEdyqUYl"
   },
   "outputs": [],
   "source": [
    "class AttnMech(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(AttnMech, self).__init__()\n",
    "\n",
    "        ratio = 2 if config.bidirectional else 1\n",
    "        lin_size = config.hidden_size * ratio\n",
    "\n",
    "        self.Wx_b = nn.Linear(lin_size, lin_size)\n",
    "        self.Vt = nn.Linear(lin_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, inputs, data=None):\n",
    "\n",
    "        # count only 1 e_t\n",
    "        if data is None:\n",
    "            x = inputs\n",
    "            x = torch.tanh(self.Wx_b(x))\n",
    "            e = self.Vt(x)\n",
    "            return e\n",
    "\n",
    "        # recount attention for full vector e\n",
    "        e = inputs\n",
    "        # (BS, seq_len, hid_size*num_dirs)\n",
    "        data = data.transpose(0, 1)\n",
    "        alphas = F.softmax(e, dim=-1).unsqueeze(1)\n",
    "        c = torch.matmul(alphas, data).squeeze()   # attetntion_vector\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BkVo6qpqUYm"
   },
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config, CRNN_model, attn_layer):\n",
    "        super(FullModel, self).__init__()\n",
    "\n",
    "        self.CRNN_model = CRNN_model\n",
    "        self.attn_layer = attn_layer\n",
    "\n",
    "        # ll_in_size, ll_out_size = HIDDEN_SIZE * GRU_NUM_DIRS, NUM_CLASSES\n",
    "        # last layer\n",
    "        ratio = 2 if config.bidirectional else 1\n",
    "        self.U = nn.Linear(config.hidden_size * ratio,\n",
    "                           config.num_classes, bias=False)\n",
    "\n",
    "    def forward(self, batch, hidden=None):\n",
    "        output, hidden = self.CRNN_model(batch, hidden)\n",
    "        # output : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "\n",
    "        e = []\n",
    "        for seq_el in output:\n",
    "            e_t = self.attn_layer(seq_el)  # (BS, 1)\n",
    "            e.append(e_t)\n",
    "        e = torch.cat(e, dim=1)           # (BS, seq_len)\n",
    "\n",
    "        c = self.attn_layer(e, output)    # attention_vector\n",
    "        Uc = self.U(c)\n",
    "        return Uc               # we will need to get probs, so we use return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "91f2f178-98a6-448c-be99-80457a76ee4a"
   },
   "outputs": [],
   "source": [
    "CRNN_model = CRNN(TaskConfig)\n",
    "attn_layer = AttnMech(TaskConfig)\n",
    "full_model = FullModel(TaskConfig, CRNN_model, attn_layer)\n",
    "full_model = full_model.to(TaskConfig.device)\n",
    "\n",
    "print(full_model)\n",
    "\n",
    "opt = torch.optim.Adam(full_model.parameters(),\n",
    "                       lr=TaskConfig.learning_rate, weight_decay=TaskConfig.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "32oooz4lqUYo",
    "outputId": "c4fdfc31-03fa-4540-9c03-4d72c6bdf714",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(full_model, opt, train_loader,\n",
    "                melspec_train, TaskConfig.device)\n",
    "\n",
    "    au_fa_fr = validation(full_model, val_loader,\n",
    "                          melspec_val, TaskConfig.device)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t55FUkOGh9pT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
